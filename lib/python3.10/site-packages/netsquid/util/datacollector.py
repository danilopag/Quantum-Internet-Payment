# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# 
# File: datacollector.py
# 
# This file is part of the NetSquid package (https://netsquid.org).
# It is subject to the NetSquid Software End User License Conditions.
# A copy of these conditions can be found in the LICENSE.md file of this package.
# 
# NetSquid Authors
# ================
# 
# NetSquid is being developed within [Quantum Internet division](https://qutech.nl/research-engineering/quantum-internet/) at QuTech.
# QuTech is a collaboration between TNO and the TUDelft.
# 
# Active authors (alphabetical):
# 
# - Tim Coopmans (scientific contributor)
# - Chris Elenbaas (software developer)
# - David Elkouss (scientific supervisor)
# - Rob Knegjens (tech lead, software architect)
# - IÃ±aki Martin Soroa (software developer)
# - Julio de Oliveira Filho (software architect)
# - Ariana Torres Knoop (HPC contributor)
# - Stephanie Wehner (scientific supervisor)
# 
# Past authors (alphabetical):
# 
# - Axel Dahlberg (scientific contributor)
# - Damian Podareanu (HPC contributor)
# - Walter de Jong (HPC contributor)
# - Loek Nijsten (software developer)
# - Martijn Papendrecht (software developer)
# - Filip Rozpedek (scientific contributor)
# - Matt Skrzypczyk (software contributor)
# - Leon Wubben (software developer)
# 
# The simulation engine of NetSquid depends on the pyDynAA package,
# which is developed at TNO by Julio de Oliveira Filho, Rob Knegjens, Coen van Leeuwen, and Joost Adriaanse.
# 
# Ariana Torres Knoop, Walter de Jong and Damian Podareanu from SURFsara have contributed towards the optimization and parallelization of NetSquid.
# 
# Hana Jirovska and Chris Elenbaas have built Python packages for MacOS.
# 
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# This file uses NumPy style docstrings: https://github.com/numpy/numpy/blob/master/doc/HOWTO_DOCUMENT.rst.txt

"""
Defines a data collector, an entity that, when triggered, stores data in a
dataframe using a user specified ``get_data_function``.

"""
from collections.abc import MutableMapping
import pydynaa
from netsquid.util.simtools import sim_time
import pandas as pd
import inspect

__all__ = [
    "DataCollector",
]


class DataCollector(pydynaa.Entity):
    """A data collector that collects data when specified events are triggered.

    Data is collected when a (combination of) :obj:`~pydynaa.core.Event`\\(s) trigger
    the user defined :attr:`~netsquid.util.datacollector.DataCollector.get_data_function`.
    The output of this function, which
    should be a dict, is stored in a :obj:`pandas.DataFrame` with the keys as
    column names. Aside from the data function output, two columns are added:
    the ``time_stamp`` at the moment of collecting and the ``entity_name`` of the
    :obj:`~pydynaa.core.Entity` that triggered this data collection.

    Data can be accessed via a :obj:`pandas.DataFrame` object or as a raw list of dicts.

    Parameters
    ----------
    get_data_function : function
        Callback function used to collect data. Should accept an event or an event expression as a parameter
        and return a dict with the collected data.
    include_time_stamp : bool, optional
        Whether to include a simulation time stamp column when data is collected.
    include_entity_name : bool, optional
        Whether to include the name of the entity that scheduled the last event that triggered
        the data collection.

    Notes
    -----
        When an :obj:`~pydynaa.core.EventExpression` triggers the data
        collection, the event passed to :attr:`~netsquid.util.datacollector.DataCollector.get_data_function`
        will be None and the ``entity_name`` in the dataframe will be set to a default value:
        'EventExpression'.

        When adding multiple triggers, an :obj:`~pydynaa.core.EventExpression`
        will be built. So even when ``combine_rule`` is "OR" and only (Entity, EventType) tuples
        are in the triggers list, the ``entity_name`` will still be :obj:`~pydynaa.core.EventExpression` and not
        the name of the triggering Entity.

    Examples
    --------
    Create a data collector, adding its get data function in different ways:

    >>> import netsquid as ns
    >>> from netsquid.util.datacollector import DataCollector
    ...
    ...
    >>> # Using a predefined function
    >>> def get_source_id(evexpr):
    ...     event = evexpr.triggered_events[-1]
    ...     return {"value": event.source.uid}
    ...
    >>> dc = DataCollector(get_source_id)
    >>> # Using a predefined function with additional arguments
    >>> dummy_entity = ns.Entity()
    >>> def get_source_equals_entity(evexpr, entity=dummy_entity):
    ...     event = evexpr.triggered_events[-1]
    ...     return {"equals": event.source == entity}
    ...
    >>> dc = DataCollector(get_source_equals_entity)
    ...
    >>> # Using a callable class
    >>> class AddingCallableClass():
    ...     def __init__(self, var_1, var_2):
    ...         self.var_1 = var_1
    ...         self.var_2 = var_2
    ...
    ...     def __call__(self, evexpr):
    ...         return {"value": self.var_1 + self.var_2}
    ...
    >>> dc = DataCollector(AddingCallableClass(var_1=1, var_2=2))

    Add a trigger when to collect data (for more examples see the ``collect_on()`` documentation):

    >>> ns.sim_reset()
    >>> dummy_entity_2 = ns.Entity()
    >>> rain_event = ns.EventType("Rain", "Rainy weather")
    >>> dc.collect_on([(dummy_entity_2, rain_event)])

    Checking the results after creating a data collector and defining when to collect data as shown above:

    >>> dummy_entity_2._schedule_now(rain_event)
    >>> ns.sim_run()
    >>> print(dc.dataframe)  # doctest: +SKIP
       time_stamp entity_name  value
    0         0.0   entity_10    3.0


    """
    column_name_time_stamp = "time_stamp"
    column_name_entity_name = "entity_name"

    def __init__(self, get_data_function, include_time_stamp=True, include_entity_name=True):
        self._priority = 3  # Be able to set higher and lower priorities: 1 is highest, 10 is lowest priority.
        self._data_buffer = []
        columns = []
        self._include_time_stamp = include_time_stamp
        self._include_entity_name = include_entity_name
        if include_time_stamp:
            columns.append(self.column_name_time_stamp)
        if include_entity_name:
            columns.append(self.column_name_entity_name)
        self._dataframe = pd.DataFrame(columns=columns)
        self._event_expression = None
        self._expr_handler = None
        self._callback_expects_event = False  # whether callback expects an event or event expression
        self.get_data_function = get_data_function

    @property
    def priority(self):
        """int: priority of this data collector.

        By default data collectors have a higher priority (default is 3) to handle
        an event than the regular event handlers (default is 5) used by waiting entities.
        Priority can be set from 1 (highest) to 10 (lowest).

        Notes
        -----
            When the priorities are equal, as is the case for regular event handlers
            that trigger on the same event, the order the handlers are called is
            not defined (in principle random).

        """
        return self._priority

    @priority.setter
    def priority(self, value):
        if not isinstance(value, int):
            raise TypeError("{} is not an int".format(value))
        if not 1 <= value <= 10:
            raise ValueError("{} is not in the range [1, 10] ".format(value))
        self._priority = value

    @property
    def get_data_function(self):
        """func: callback function used to collect data. Should accept an event (expression) as a parameter\
                and return a dict with the collected data."""
        return self._get_data_function

    @get_data_function.setter
    def get_data_function(self, value):
        if not callable(value):
            raise TypeError("{} is not a callable function")
        _arguments = inspect.getfullargspec(value)[0]
        self._callback_expects_event = ("event" in _arguments)
        # TODO deprecate 'event' parameter
        # if "event" in _arguments:
        #    warn_deprecated()
        self._get_data_function = value

    @property
    def databuffer(self):
        """list: data collected since the last call to :attr:`~netsquid.util.datacollector.DataCollector.dataframe`.

        Notes
        -----
            This list is cleared after every call to :attr:`~netsquid.util.datacollector.DataCollector.dataframe`.

        """
        return self._data_buffer

    @property
    def dataframe(self):
        """:obj:`pandas.DataFrame`: DataFrame of all collected data.

        When the :attr:`~netsquid.util.datacollector.DataCollector.get_data_function` is called,
        its output (a dict of name: value) will
        be stored together with current ``time_stamp`` and triggering ``entity_name`` in a
        buffer (a list of dicts). This is done to increase the performance: appending
        multiple rows of data one by one is slower than appending them all at once.

        When dataframe is called, it will check if there is data in the buffer.
        If there is buffered data, this will be added to the dataframe and the buffer
        is cleared.

        Notes
        -----
            In the process of adding new data, a new :obj:`pandas.DataFrame`
            instance is created. When there is no buffered data, no new instance will be created.

        """
        if len(self._data_buffer) > 0:
            data_buffer = pd.DataFrame(self._data_buffer)
            self._dataframe = pd.concat([self._dataframe, data_buffer],
                                        ignore_index=True,
                                        sort=False)
            self._data_buffer.clear()
        return self._dataframe

    def collect_on(self, triggers, combine_rule=None):
        """Define when to collect data by waiting for events and/or event expressions.

        All triggers are converted to an event expression.

        Parameters
        ----------
        triggers : list of tuples (:obj:`~pydynaa.core.Entity`,\
                   :obj:`~pydynaa.core.EventType`) or :obj:`~pydynaa.core.EventExpression`
            The source entity/entities or event expression(s) that should trigger data collection.
        combine_rule : str, optional
            Whether to collect data when all ("AND") or any ("OR") of the triggers trigger. When multiple
            triggers are specified, you have to define this because there is no default rule set.

        Examples
        --------
        Create a data collector and set triggers in different ways, where each
        call to ``collect_on`` overwrites the previous triggers:

        >>> test_entity = pydynaa.Entity()
        >>> rain_event = pydynaa.EventType("Rain", "Rainy weather")
        >>> sun_event = pydynaa.EventType("Sun", "Sunny weather")
        >>> evexpr_rain = pydynaa.EventExpression(event_type=rain_event)
        >>> evexpr_sun = pydynaa.EventExpression(event_type=sun_event)
        >>> evexpr_rainbow = evexpr_rain & evexpr_sun
        ...
        >>> def get_weather_conditions(evexpr):
        ...     events = evexpr.triggered_events[-1]
        ...     conditions = "& ".join([event.type.name for event in events])
        ...     return {"conditions": conditions}
        ...
        >>> dc = DataCollector(get_weather_conditions)
        ...
        >>> # Collecton a single (entity, event type) tuple
        >>> dc.collect_on([(test_entity, rain_event)])
        ...
        >>> # Collect on a single EventExpression
        >>> dc.collect_on([evexpr_rainbow])
        ...
        >>> # Collect on multiple triggers
        >>> dc.collect_on([(test_entity, rain_event), evexpr_sun], "OR")
        ...
        >>> # Collect on a combination of triggers
        >>> dc.collect_on([(test_entity, sun_event), evexpr_rainbow], "AND")

        Notes
        -----
            All previous triggers of this data collector will be dismissed when calling this function.

        """
        if not isinstance(triggers, list):
            triggers = [triggers]
        elif len(triggers) == 0:
            raise ValueError("collect_on() called with incorrect argument(s): "
                             "triggers should not be an empty list.")
        if len(triggers) == 1:
            combine_rule = "OR"
        new_event_expression = self._create_event_expression(triggers, combine_rule)
        self._collect_on_event_expression(new_event_expression)

    def reset(self):
        """Reset this data collector, i.e. do not collect data for any previous defined trigger."""
        # Dismiss waiting EventExpression.
        if self._event_expression is not None:
            self._dismiss(self._expr_handler, expression=self._event_expression)
            self._event_expression = None

    def _check_trigger_is_source_event_combination(self, trigger):
        # Check if trigger is of the form (Entity, EventType).
        if len(trigger) != 2:
            raise ValueError("collect_on() was called with a tuple which should have "
                             "length 2: (source, event type), not: {}.".format(trigger))
        if not isinstance(trigger[0], pydynaa.Entity) and not isinstance(trigger[1], pydynaa.EventType):
            raise TypeError("collect_on() was called with a tuple which should have types "
                            "(pydynaa.Entity, pydynaa.EventType), not: {}."
                            .format((type(trigger[0]), type(trigger[1]))))

    def _create_event_expression(self, triggers, combine_rule):
        # Build an EventExpression of all triggers using the combine rule.
        if not isinstance(combine_rule, str) or combine_rule.upper() not in ("AND", "OR"):
            raise ValueError("When adding multiple sources and event_types, you "
                             "need to define a combine_rule: 'AND' or 'OR', not: {}."
                             .format(combine_rule))
        combine_rule = combine_rule.upper()
        new_expression = None
        for trigger in triggers:
            # Build EventExpression
            if isinstance(trigger, tuple):
                self._check_trigger_is_source_event_combination(trigger)
                source, evtype = trigger
                expr = pydynaa.EventExpression(source=source, event_type=evtype)
                if new_expression is None:
                    new_expression = expr
                else:
                    if combine_rule == "AND":
                        new_expression = new_expression & expr
                    else:
                        new_expression = new_expression | expr
            elif isinstance(trigger, pydynaa.EventExpression):
                if new_expression is None:
                    new_expression = trigger
                else:
                    if combine_rule == "AND":
                        new_expression = new_expression & trigger
                    else:
                        new_expression = new_expression | trigger
            else:
                raise TypeError("collect_on() called with incorrect argument(s): triggers "
                                "should be a list of tuples (source, event type) or and "
                                "EventExpression, not: {}.".format(trigger))
        return new_expression

    def _collect_on_event_expression(self, event_expression):
        # Add an EventExpression to be monitored.
        self.reset()
        self._event_expression = event_expression
        self._expr_handler = pydynaa.ExpressionHandler(self._callback, priority=self._priority)
        self._wait(self._expr_handler, expression=self._event_expression)

    def _callback(self, evexpr):
        # Callback function of the triggered expression:
        # stores data with the current simulation time stamp and source as string.
        event = evexpr.triggered_events[-1]
        try:
            source_name = str(event.source)
        except LookupError:
            source_name = "Expired entity"
        if self._callback_expects_event:
            data = self._get_data_function(event=event)
        else:
            data = self._get_data_function(evexpr)
        if data is None:
            return
        elif isinstance(data, MutableMapping):
            if self._include_entity_name:
                data[self.column_name_entity_name] = source_name
            if self._include_time_stamp:
                data[self.column_name_time_stamp] = sim_time()
            if len(data) > 0:
                self._data_buffer.append(data)
        else:
            raise TypeError("get_data_function returned object with incorrect type. "
                            "Should be None, MutableMapping not: {}".format(type(data)))
